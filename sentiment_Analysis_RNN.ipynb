{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary libraries**"
      ],
      "metadata": {
        "id": "ChbnkZUvBsnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "51P5CdVkBymS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load IMDB dataset**"
      ],
      "metadata": {
        "id": "hsKwlc7XB10S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # Number of words to keep in vocabulary\n",
        "max_length = 100  # Maximum review length\n",
        "embedding_dim = 32\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60OfT4nOB33i",
        "outputId": "aa9560be-e113-47f8-c20a-251c1dcb0ff7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pad sequences to ensure uniform input size**"
      ],
      "metadata": {
        "id": "ZWqeQeghCDpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "WBd76Xa8CGTi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build the RNN model (using LSTM)**"
      ],
      "metadata": {
        "id": "zW3NO3dwCK6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    keras.layers.LSTM(64, return_sequences=False),  # Using LSTM instead of SimpleRNN\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzmdevA1CNWq",
        "outputId": "12bcd772-2378-41c9-eb06-119053bc6936"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compile the model**"
      ],
      "metadata": {
        "id": "FxpMSnlkCQRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0z5xKe-xCSWC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the model**"
      ],
      "metadata": {
        "id": "ZWFKxvGoCUZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojwsdkZCbiC",
        "outputId": "598b0221-290b-4e6f-c5cf-b9746f204424"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 99ms/step - accuracy: 0.6456 - loss: 0.5970 - val_accuracy: 0.7933 - val_loss: 0.4517\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 99ms/step - accuracy: 0.8688 - loss: 0.3327 - val_accuracy: 0.7984 - val_loss: 0.4545\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 96ms/step - accuracy: 0.8911 - loss: 0.2886 - val_accuracy: 0.8076 - val_loss: 0.4433\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 96ms/step - accuracy: 0.9134 - loss: 0.2367 - val_accuracy: 0.7948 - val_loss: 0.4661\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 96ms/step - accuracy: 0.9299 - loss: 0.1980 - val_accuracy: 0.8018 - val_loss: 0.5442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the model**"
      ],
      "metadata": {
        "id": "vMXmFT-iCfcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9LMyVdgC0NC",
        "outputId": "b892fa6f-f6c7-4871-e5b4-842783228a66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.7991 - loss: 0.5466\n",
            "Test Accuracy: 0.8018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the model**"
      ],
      "metadata": {
        "id": "kW_lX1ILC2rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/sentiment_rnn_model.h5')\n",
        "print(\"Model saved to /content/sentiment_rnn_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIjXb_uXEAz6",
        "outputId": "746fcf5c-be4c-46db-a26a-d7c3921ce7a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/sentiment_rnn_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load IMDB word index (to convert words to numbers)**"
      ],
      "metadata": {
        "id": "4LdV55I9EDux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index = {k: (v + 3) for k, v in word_index.items()}  # Shift indices\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "reverse_word_index = {v: k for k, v in word_index.items()}  # Reverse mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIuhgWPEFbQ",
        "outputId": "5186b091-2094-431c-9ab4-ff38e73b7590"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Helper Functions**"
      ],
      "metadata": {
        "id": "-Khl1CWmEMrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess custom text\n",
        "def encode_text(text):\n",
        "    words = text.lower().split()\n",
        "    encoded = [word_index.get(word, 2) for word in words]  # Convert words to numbers\n",
        "    padded = pad_sequences([encoded], maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded"
      ],
      "metadata": {
        "id": "Vh7icxgtERG4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict sentiment from user input\n",
        "def predict_sentiment(text):\n",
        "    processed_text = encode_text(text)\n",
        "    prediction = model.predict(processed_text)[0][0]  # Get probability\n",
        "    sentiment = \"Positive 😀\" if prediction > 0.5 else \"Negative 😞\"\n",
        "    print(f\"\\nReview: {text}\")\n",
        "    print(f\"Sentiment: {sentiment} (Confidence: {prediction:.4f})\")"
      ],
      "metadata": {
        "id": "m9ChlvXrETNY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example test**"
      ],
      "metadata": {
        "id": "hHcJorXwEaT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-5lb72PBQXv",
        "outputId": "75eda735-6235-474c-e4e5-2b3d8d10013f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
            "\n",
            "Review: This movie was fantastic! I really enjoyed it.\n",
            "Sentiment: Positive 😀 (Confidence: 0.8192)\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"This movie was fantastic! I really enjoyed it.\"\n",
        "predict_sentiment(sample_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Allow user to input their own review**"
      ],
      "metadata": {
        "id": "9_bCcKqqEcsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_review = input(\"Enter a movie review: \")\n",
        "predict_sentiment(user_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TztbunU6EeCJ",
        "outputId": "e4d67ae2-a008-4043-c68b-52f746613e48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a movie review: this movie was bad for me\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "Review: this movie was bad for me\n",
            "Sentiment: Negative 😞 (Confidence: 0.1590)\n"
          ]
        }
      ]
    }
  ]
}